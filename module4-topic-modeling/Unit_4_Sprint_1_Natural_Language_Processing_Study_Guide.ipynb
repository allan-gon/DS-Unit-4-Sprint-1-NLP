{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "enodNfbMIxzN"
   },
   "source": [
    "This study guide should reinforce and provide practice for all of the concepts you have seen in the past week. There are a mix of written questions and coding exercises, both are equally important to prepare you for the sprint challenge as well as to be able to speak on these topics comfortably in interviews and on the job.\n",
    "\n",
    "If you get stuck or are unsure of something remember the 20 minute rule. If that doesn't help, then research a solution with google and stackoverflow. Only once you have exausted these methods should you turn to your Team Lead - they won't be there on your SC or during an interview. That being said, don't hesitate to ask for help if you truly are stuck.\n",
    "\n",
    "Have fun studying!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TfidfVectorizer().fit_transform([['a', 'word'],['more', 'words']]).todense()\n",
    "# you can't straight up pass list of stringsm you need to pass a string and let\n",
    "# it figure it out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mjVNoILlDD83"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import spacy\n",
    "from collections import Counter\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 242
    },
    "colab_type": "code",
    "id": "LMQBp_ddC9CX",
    "outputId": "688a6986-7a3c-4a90-9a7d-c93f36cf7bb0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (2351, 6) \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Strain</th>\n",
       "      <th>Type</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Effects</th>\n",
       "      <th>Flavor</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100-Og</td>\n",
       "      <td>hybrid</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Creative,Energetic,Tingly,Euphoric,Relaxed</td>\n",
       "      <td>Earthy,Sweet,Citrus</td>\n",
       "      <td>$100 OG is a 50/50 hybrid strain that packs a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>98-White-Widow</td>\n",
       "      <td>hybrid</td>\n",
       "      <td>4.7</td>\n",
       "      <td>Relaxed,Aroused,Creative,Happy,Energetic</td>\n",
       "      <td>Flowery,Violet,Diesel</td>\n",
       "      <td>The ‘98 Aloha White Widow is an especially pot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1024</td>\n",
       "      <td>sativa</td>\n",
       "      <td>4.4</td>\n",
       "      <td>Uplifted,Happy,Relaxed,Energetic,Creative</td>\n",
       "      <td>Spicy/Herbal,Sage,Woody</td>\n",
       "      <td>1024 is a sativa-dominant hybrid bred in Spain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13-Dawgs</td>\n",
       "      <td>hybrid</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Tingly,Creative,Hungry,Relaxed,Uplifted</td>\n",
       "      <td>Apricot,Citrus,Grapefruit</td>\n",
       "      <td>13 Dawgs is a hybrid of G13 and Chemdawg genet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24K-Gold</td>\n",
       "      <td>hybrid</td>\n",
       "      <td>4.6</td>\n",
       "      <td>Happy,Relaxed,Euphoric,Uplifted,Talkative</td>\n",
       "      <td>Citrus,Earthy,Orange</td>\n",
       "      <td>Also known as Kosher Tangie, 24k Gold is a 60%...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Strain    Type  Rating                                     Effects  \\\n",
       "0          100-Og  hybrid     4.0  Creative,Energetic,Tingly,Euphoric,Relaxed   \n",
       "1  98-White-Widow  hybrid     4.7    Relaxed,Aroused,Creative,Happy,Energetic   \n",
       "2            1024  sativa     4.4   Uplifted,Happy,Relaxed,Energetic,Creative   \n",
       "3        13-Dawgs  hybrid     4.2     Tingly,Creative,Hungry,Relaxed,Uplifted   \n",
       "4        24K-Gold  hybrid     4.6   Happy,Relaxed,Euphoric,Uplifted,Talkative   \n",
       "\n",
       "                      Flavor  \\\n",
       "0        Earthy,Sweet,Citrus   \n",
       "1      Flowery,Violet,Diesel   \n",
       "2    Spicy/Herbal,Sage,Woody   \n",
       "3  Apricot,Citrus,Grapefruit   \n",
       "4       Citrus,Earthy,Orange   \n",
       "\n",
       "                                         Description  \n",
       "0  $100 OG is a 50/50 hybrid strain that packs a ...  \n",
       "1  The ‘98 Aloha White Widow is an especially pot...  \n",
       "2  1024 is a sativa-dominant hybrid bred in Spain...  \n",
       "3  13 Dawgs is a hybrid of G13 and Chemdawg genet...  \n",
       "4  Also known as Kosher Tangie, 24k Gold is a 60%...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/bundickm/Study-Guides/master/data/cannabis.csv')\n",
    "print('Shape:', df.shape, '\\n')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1024 is a sativa-dominant hybrid bred in Spain by Medical Seeds Co. The breeders claim to guard the secret genetics due to security reasons, but regardless of its genetic heritage, 1024 is a THC powerhouse with a sweet and spicy bouquet. Subtle fruit flavors mix with an herbal musk to produce uplifting sativa effects. One specific phenotype is noted for having a pungent odor that fills a room, similar to burning incense.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Description[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zbpf-sf-DjRi"
   },
   "source": [
    "# Tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S8pe3aGUJUkI"
   },
   "source": [
    "## Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C3GHPBZ4I3h5"
   },
   "source": [
    "Define the following terms in your own words, do not simply copy and paste a definition found elsewhere but reword it to be understandable and memorable to you. *Double click the markdown to add your definitions.*\n",
    "<br/><br/>\n",
    "\n",
    "**Natural Language Processing**: Taking human speak and vectorizing it to make predictions\n",
    "\n",
    "**Token**: The words that will be vetorized\n",
    "\n",
    "**Corpus**: The vocabulary\n",
    "\n",
    "**Stopwords**: Words you dont want to include in the analysis\n",
    "\n",
    "**Statistical Trimming**: Excluding extremes\n",
    "\n",
    "**Stemming**: The .strip() of cleaning tokens\n",
    "\n",
    "**Lemmatization**: Transforming a token into it's root word\n",
    "\n",
    "**Vectorization**: Taking tokens and representing them as numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jbXlWbA3JWuU"
   },
   "source": [
    "## Questions of Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yjm-Ab4sJaOs"
   },
   "source": [
    "1. What are at least 4 common cleaning tasks you need to do when creating tokens?\n",
    " 1. `Your Answer Here`\n",
    " 2. `Your Answer Here`\n",
    " 3. `Your Answer Here`\n",
    " 4. `Your Answer Here`\n",
    "\n",
    "2. Why is it important to apply custom stopwords to our dataset in addition to the ones that come in a library like spaCy?\n",
    "\n",
    "My data carries a common theme, therfore common words, that spacy did not plan for so it would behoove me to remove custom stop words\n",
    "\n",
    "3. Explain the tradeoffs between statistical trimming, stemming, and lemmatizing.\n",
    "\n",
    "Time to compute, lemmatization has the longest time. Trimming lowers time by shortenning the corpus. Stemming sucks\n",
    "\n",
    "4. Why do we need to vectorize our documents?\n",
    "\n",
    "Computers don't know how to use words to make prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fn3Z587YMwnE"
   },
   "source": [
    "## Practice Problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ii_LYpeoDrTp"
   },
   "source": [
    "Write a function to tokenize the `Description` column. Make sure to include the following:\n",
    "- Return the tokens in an iterable structure\n",
    "- Normalize the case\n",
    "- Remove non-alphanumeric characters such as punctuation, whitespace, unicode, etc.\n",
    "- Apply stopwords and make sure to add stopwords specific to this dataset\n",
    "- Lemmatize the tokens before returning them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rgt9aT-TDFcq"
   },
   "outputs": [],
   "source": [
    "stops = nlp.Defaults.stop_words.union(['weed', 'blunt', 'marijuana', 'high'])\n",
    "\n",
    "def tokenize(text):\n",
    "    lower = text.lower()\n",
    "    subbed = re.sub(r'[^\\w\\s-]', '', lower)\n",
    "    temp = []\n",
    "    for word in nlp(subbed):\n",
    "        if ((word not in stops) and\n",
    "            (not word.is_punct) and\n",
    "            (word.pos_ != 'PRON')):\n",
    "            temp.append(word.lemma_)\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['tokens'] = df['Description'].apply(tokenize)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M4x9xuBVF4Nh"
   },
   "source": [
    "# Use the function below to create a `word_count` dataframe based off the `df['Tokens']` column you created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6zu2dfbcGz2Y"
   },
   "outputs": [],
   "source": [
    "def count(docs):\n",
    "        word_counts = Counter()\n",
    "        appears_in = Counter()\n",
    "        total_docs = len(docs)\n",
    "\n",
    "        for doc in docs:\n",
    "            word_counts.update(doc)\n",
    "            appears_in.update(set(doc))\n",
    "\n",
    "        temp = zip(word_counts.keys(), word_counts.values())\n",
    "        wc = pd.DataFrame(temp, columns = ['word', 'count'])\n",
    "\n",
    "        wc['rank'] = wc['count'].rank(method='first', ascending=False)\n",
    "        total = wc['count'].sum()\n",
    "\n",
    "        wc['pct_total'] = wc['count'].apply(lambda x: x / total)\n",
    "        \n",
    "        wc = wc.sort_values(by='rank')\n",
    "        wc['cul_pct_total'] = wc['pct_total'].cumsum()\n",
    "\n",
    "        t2 = zip(appears_in.keys(), appears_in.values())\n",
    "        ac = pd.DataFrame(t2, columns=['word', 'appears_in'])\n",
    "        wc = ac.merge(wc, on='word')\n",
    "\n",
    "        wc['appears_in_pct'] = wc['appears_in'].apply(lambda x: x / total_docs)\n",
    "        \n",
    "        return wc.sort_values(by='rank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "94lL-w_uGzzm"
   },
   "outputs": [],
   "source": [
    "# count_df = df['tokens'].apply(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JPPxVzGIHUF8"
   },
   "source": [
    "Run the line of code below, and then explain how to interpret the graph.\n",
    "\n",
    "```\n",
    "Your Answer Here\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DWqbuy68Ib0S"
   },
   "outputs": [],
   "source": [
    "# sns.lineplot(x='rank', y='cul_pct_total', data=count_df);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I-_e03NrMjIO"
   },
   "source": [
    "# Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tQRlWI7UM4ah"
   },
   "source": [
    "## Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "djODVPGjM4ao"
   },
   "source": [
    "Define the following terms in your own words, do not simply copy and paste a definition found elsewhere but reword it to be understandable and memorable to you. *Double click the markdown to add your definitions.*\n",
    "<br/><br/>\n",
    "\n",
    "**Vectorization**: Taking tokens and representing them as numbers\n",
    "\n",
    "**Document Term Matrix (DTM)**: Matrix that represents each document's tokens\n",
    "\n",
    "**Latent Semantic Analysis**: `Your Answer Here`\n",
    "\n",
    "**Term Frequency - Inverse Document Frequency (TF-IDF)**: `Your Answer Here`\n",
    "\n",
    "**Word Embedding**: `Your Answer Here`\n",
    "\n",
    "**N-Gram**: `Your Answer Here`\n",
    "\n",
    "**Skip-Gram**: `Your Answer Here`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lOsi6xE4M-cS"
   },
   "source": [
    "## Questions of Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3_Atsw1bM-cY"
   },
   "source": [
    "1. Why do we need to vectorize our documents?\n",
    "\n",
    "Because machinee don't know what words mean\n",
    "\n",
    "2. How is TF-IDF different from simple word frequency? Why do we use TF-IDF over word frequency?\n",
    "\n",
    "It's some proportion of the word's appearence in the whole corpus instead of just how many times it appears in 1 doc\n",
    "\n",
    "3. Why might we choose a word embedding approach over a bag-of-words approach when it comes to vectorization?\n",
    "\n",
    "Better results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SogHDgfhMTsc"
   },
   "source": [
    "## Practice Problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a7QrjSwIMYzB"
   },
   "source": [
    "Use the dataframe `df` above to complete the following."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1BTQbHxIMeQN"
   },
   "source": [
    "Vectorize the `Tokens` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ka0AywjNMBMI"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tfidfvectorizer',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=<function tokenize at 0x7f3ae5679b70>,\n",
       "                                 use_idf=True, vocabulary=None)),\n",
       "                ('nearestneighbors',\n",
       "                 NearestNeighbors(algorithm='auto', leaf_size=30,\n",
       "                                  metric='minkowski', metric_params=None,\n",
       "                                  n_jobs=-1, n_neighbors=5, p=2, radius=1.0))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neigh_pipe = make_pipeline(TfidfVectorizer(tokenizer=tokenize), NearestNeighbors(n_jobs=-1));\n",
    "neigh_pipe.fit(df['Description'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B26eq5wKMrF4"
   },
   "source": [
    "Build a Nearest Neighbors model from your dataframe and then find the 5 nearest neighbors to the strain \"100-OG\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JcwURJatMp7B"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1., 1., 1., 1., 1.]]), array([[ 105,  662, 1186,  352, 1553]]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neigh_pipe.named_steps['nearestneighbors'].kneighbors(neigh_pipe.named_steps['tfidfvectorizer'].transform([\"100-OG\"]).todense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PvGLfBxDW6D7"
   },
   "source": [
    "You will be putting together a classification model below, but before you do you'll need a baseline. Run the line of code below and then find the normalized value counts for the `Rating` column in `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6zsEPQgRZKmH"
   },
   "outputs": [],
   "source": [
    "df['Rating'] = df['Rating'].round().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RCPof-7VZOMt"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Rating'>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(df.Rating)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hboaEX03Z_w5"
   },
   "source": [
    "What is the baseline accuracy?\n",
    "```\n",
    "Your Answer Here\n",
    "```\n",
    "\n",
    "Visualize the rating counts from above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9PGmJSMqZxo0"
   },
   "outputs": [],
   "source": [
    "log_pipe = make_pipeline(TfidfVectorizer(tokenizer=tokenize), LogisticRegression(n_jobs=-1, random_state=42));\n",
    "log_pipe.fit(df.Description, df.Rating);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WwPg1cpShKNA"
   },
   "source": [
    "Use your vectorized tokens in the `df` dataframe to train a classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "awu-ujvvhips"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.8454106280193237\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train score: {log_pipe.score(df.Description, df.Rating)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kGhSLJ5Fhlg9"
   },
   "source": [
    "Predict the score of the fake strain description below.\n",
    "\n",
    "```\n",
    "'Afgooey, also known as Afgoo, is a potent indica strain that is believed to descend from an Afghani indica and Maui Haze. \n",
    "Its sativa parent may lend Afgoo some uplifting, creative qualities, but this strain undoubtedly takes after its indica \n",
    "parent as it primarily delivers relaxing, sleepy effects alongside its earthy pine flavor. Growers hoping to cultivate Afgoo \n",
    "may have a better chance of success indoors, but this indica can also thrive in Mediterranean climates outdoors.'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rAHaMGjBiG-h"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_pipe.predict([\"\"\"Afgooey, also known as Afgoo, is a potent indica strain that is believed to descend from an Afghani indica and Maui Haze. \n",
    "Its sativa parent may lend Afgoo some uplifting, creative qualities, but this strain undoubtedly takes after its indica \n",
    "parent as it primarily delivers relaxing, sleepy effects alongside its earthy pine flavor. Growers hoping to cultivate Afgoo \n",
    "may have a better chance of success indoors, but this indica can also thrive in Mediterranean climates outdoors.\"\"\"])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RGnLTUL8ik4V"
   },
   "source": [
    "# Topic Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rfXxSZSDk-Sh"
   },
   "source": [
    "## Questions of Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hlcEfmnyk-St"
   },
   "source": [
    "1. What is Latent Dirichlet Allocation? What is another name for LDA in NLP?\n",
    "```\n",
    "Your Answer Here\n",
    "```\n",
    "\n",
    "2. How do interpret the results of a topic modeling output?\n",
    "```\n",
    "Your Answer Here\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lAf8cmNFl_n5"
   },
   "source": [
    "## Practice Problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RIeP8NyHmAU8"
   },
   "source": [
    "Find the top 5 topics of the `Description` column using LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e-8zDKA_mAba"
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim import corpora\n",
    "from gensim.models.ldamulticore import LdaMulticore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['token'] = df.Description.apply(tokenize)\n",
    "id2word = corpora.Dictionary(df['token'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word.filter_extremes(no_below=15, no_above=0.85)\n",
    "corpus = [id2word.doc2bow(text) for text in df['token']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LdaMulticore(corpus=corpus,\n",
    "                   id2word=id2word,\n",
    "                   num_topics=5,\n",
    "                   passes=50, \n",
    "                   workers=12\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [re.findall(r'\"[^\"]*\"', t[1]) for t in lda.print_topics(5)]\n",
    "topic_labels = [', '.join(t[0:5]) for t in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis.gensim\n",
    "\n",
    "pyLDAvis.enable_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/allan/.local/share/virtualenvs/u4-s1-1fz81KSO/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# pyLDAvis.gensim.prepare(lda, corpus, id2word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ADcqbM9FmiVg"
   },
   "source": [
    "In a short paragraph, explain how to interpret the first topic your model came up with. If your topic words are difficult to interpret, explain how you could clean up the descriptions to improve your topics\n",
    "\n",
    "Points out like 5 strain. 1 is kush, 2 & 4 are indica, 3 is sativa, 4 is diesel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "suchG0sEm8lU"
   },
   "source": [
    "Use `pyLDAvis` to create a visualization to help you interpret your topic modeling results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3f5LbisKnRPV"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HafoLqwHnR5M"
   },
   "source": [
    "Explain how to interpret the results of `pyLDAvis`\n",
    "\n",
    "It cluster the docs into n topics so what are most of the descriptions about given tfidf the descrip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ANxVUGU2nYsB"
   },
   "source": [
    "Create at least 1 more visualization to help you interpret the results of your topic modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WEsF_ZMIm7mC"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Unit_4_Sprint_1_Natural_Language_Processing_Study_Guide.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
